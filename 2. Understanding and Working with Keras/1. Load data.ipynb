{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step in the deep learning process with Keras\n",
    "# Load the data\n",
    "# Code demonstration\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "#from keras.layers.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "# Load data\n",
    "np.random.seed(100) # for reproducibility\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# cifar10 has images of various objects and animals\n",
    "# for each image, width = 32, height = 32, number of channels(RGB) = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second step is to preprocess the data\n",
    "# flatten the data, MLP doesn't use the 2D Structure of the data, 3072 = 3*32*32\n",
    "X_train = X_train.reshape(50000, 3072) # 500000 images for training\n",
    "X_test = X_test.reshape(10000, 3072) # 10,000 images for test\n",
    "\n",
    "# Gaussian normalization (Z-score)\n",
    "X_train = (X_train-np.mean(X_train))/np.std(X_train)\n",
    "X_test = (X_test - np.mean(X_test)/np.std(X_test))\n",
    "\n",
    "# Convert class vectors to binary class matrices i.e. one-hat vectors\n",
    "labels = 10 # 10 unique labels (0-9)\n",
    "Y_train = tf.compat.v1.keras.utils.to_categorical(y_train, labels)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test, labels)\n",
    "# tf.keras.utils.to_categorical converts a class vector (integers) to a binary class matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "# Create a sequential model and then add layers\n",
    "# first hidden layer\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(3072, ))) # 3*32*32\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4)) # regularization\n",
    "# second hidden layer\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2)) # reularization\n",
    "# last layer with 10 outputs , each output per class\n",
    "model.add(Dense(labels))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Q: how did 3072 variables become three layers of 512, 120 and 10?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One image has 3 channels (RGB) and in each channel, the images has 32 by 32 pixels\n",
    "i.e. 1024 pixels\n",
    "So each image has 3072 pixels\n",
    "\n",
    "With the help of 3,072 features, you need to predict the probability of\n",
    "label1 (Digit 0), label2 (Digit 1), and so on.\n",
    "\n",
    "The last activation function (sigmoid, as shown\n",
    "earlier) gives 0 for nine outputs and 1 for only one output.\n",
    "\n",
    "3,072 features ➤ 512 nodes ➤ 120 nodes ➤ 10 nodes\n",
    "\n",
    "A dense class defines fully connected layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
